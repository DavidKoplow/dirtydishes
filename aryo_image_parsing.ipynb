{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FastSAM.fastsam import FastSAM, FastSAMPrompt\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from FastSAM.utils.tools import convert_box_xywh_to_xyxy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ imgsz=[2872] must be multiple of max stride 32, updating to [2880]\n",
      "image 1/1 /Users/aryomanpatel/Desktop/Coding Stuff/dirtydishes/FastSAM/images/imageForSegmentation.jpg: 1536x2880 115 objects, 19495.2ms\n",
      "Speed: 45.7ms preprocess, 19495.2ms inference, 3854.0ms postprocess per image at shape (1, 3, 2880, 2880)\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cpu\"\n",
    "model = FastSAM(\"./FastSAM/FastSAM.pt\")\n",
    "IMAGE_PATH = \"./FastSAM/images/imageForSegmentation.jpg\"\n",
    "\n",
    "everything_results = model(IMAGE_PATH, device=DEVICE, retina_masks=True, imgsz=2872, conf=0.4, iou=0.9,)\n",
    "prompt_process = FastSAMPrompt(IMAGE_PATH, everything_results, device=DEVICE)\n",
    "\n",
    "ann = prompt_process.everything_prompt()\n",
    "\n",
    "prompt_process.plot(annotations = ann, output_path = \"./FastSAM/output/ipynb_annotated.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([115, 1532, 2872])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./FastSAM/images/imageForSegmentation.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_num = 56\n",
    "\n",
    "mask = ann[mask_num]\n",
    "\n",
    "cloned_image = image.copy()\n",
    "image_as_tensor = torch.from_numpy(cloned_image).permute(2, 0, 1).float()\n",
    "mask.unsqueeze(0)\n",
    "mask = mask.repeat(3, 1, 1)\n",
    "image_as_tensor[:, mask[0] > 0] + 0.5\n",
    "\n",
    "image_as_tensor = torch.clamp(image_as_tensor, 0, 1)\n",
    "\n",
    "image_as_tensor = image_as_tensor.permute(1, 2, 0).numpy()\n",
    "image_as_tensor = np.clip(image_as_tensor, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # Optional: Adjust figure size as needed\n",
    "plt.imshow(image_as_tensor)\n",
    "plt.axis('off')  # Hide axis for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def sm(im):\n",
    "    Image.fromarray(im).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class args_init:\n",
    "    def __init__(self):\n",
    "        self.model_path = \"./FastSAM/FastSAM.pt\"\n",
    "        self.img_path = \"./FastSAM/images/imageForSegmentation.jpg\"\n",
    "        self.imgsz = 1024\n",
    "        self.iou = 0.9\n",
    "        self.text_prompt = None\n",
    "\n",
    "        self.conf = 0.4\n",
    "        self.output = \"./output/\"\n",
    "        self.point_prompt=\"[[0,0]]\"\n",
    "\n",
    "        self.randomcolor = True\n",
    "\n",
    "\n",
    "        self.point_label = \"[0]\"\n",
    "        self.box_prompt = \"[[0,0,0,0]]\"\n",
    "        self.better_quality = False\n",
    "        self.device = torch.device(\n",
    "            \"cuda\"\n",
    "            if torch.cuda.is_available()\n",
    "            else \"mps\"\n",
    "            if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "        self.retina = True\n",
    "        self.withContours = False\n",
    "\n",
    "args = args_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryomanpatel/miniconda3/envs/FastSAM/lib/python3.9/site-packages/ultralytics/yolo/utils/torch_utils.py:94: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  elif mps and getattr(torch, 'has_mps', False) and torch.backends.mps.is_available() and TORCH_2_0:\n",
      "\n",
      "0: 576x1024 103 objects, 739.1ms\n",
      "Speed: 25.3ms preprocess, 739.1ms inference, 389.4ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "model = FastSAM(args.model_path)\n",
    "args.point_prompt = ast.literal_eval(args.point_prompt)\n",
    "args.box_prompt = convert_box_xywh_to_xyxy(ast.literal_eval(args.box_prompt))\n",
    "args.point_label = ast.literal_eval(args.point_label)\n",
    "input = Image.open(args.img_path)\n",
    "input = input.convert(\"RGB\")\n",
    "everything_results = model(\n",
    "    input,\n",
    "    device=args.device,\n",
    "    retina_masks=args.retina,\n",
    "    imgsz=args.imgsz,\n",
    "    conf=args.conf,\n",
    "    iou=args.iou    \n",
    "    )\n",
    "bboxes = None\n",
    "points = None\n",
    "point_label = None\n",
    "prompt_process = FastSAMPrompt(input, everything_results, device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_number = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm(prompt_process.plot_to_result(\n",
    "        ann[ann_number:ann_number + 1, :, :], \n",
    "        bboxes, \n",
    "        points, \n",
    "        point_label, \n",
    "        True,\n",
    "        args.better_quality, \n",
    "        args.retina, \n",
    "        args.withContours,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = ann[ann_number, :, :]\n",
    "annotation = annotation.numpy()\n",
    "annotation = np.uint8(annotation)\n",
    "countours, hiearchy = cv2.findContours(annotation, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = np.ones((50,50), np.uint8)\n",
    "# erosion= cv2.morphologyEx(annotation,cv2.MORPH_OPEN, kernel, iterations = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_figure = 0\n",
    "for i in range(1, len(countours)):\n",
    "    if len(countours[i]) > len(countours[max_figure]):\n",
    "        max_figure = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = countours[max_figure]\n",
    "M = cv2.moments(cnt)\n",
    "cx = int(M['m10']/M['m00'])\n",
    "cy = int(M['m01']/M['m00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2389, 1230)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx, cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = prompt_process.plot_to_result(\n",
    "        ann[ann_number:ann_number + 1, :, :], \n",
    "        bboxes, \n",
    "        points, \n",
    "        point_label, \n",
    "        True,\n",
    "        args.better_quality, \n",
    "        args.retina, \n",
    "        args.withContours,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = cv2.convexHull(cnt)\n",
    "hull_points = hull.reshape(-1, 2)\n",
    "# Plot the hull points\n",
    "hull = cv2.convexHull(cnt)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(res)\n",
    "plt.plot(hull_points[:, 0], hull_points[:, 1], 'ro')  # Plot points as red circles\n",
    "\n",
    "# Optionally, draw lines connecting the points to visualize the hull shape\n",
    "for i in range(len(hull_points)):\n",
    "    # Connect each point to the next, and the last point to the first\n",
    "    next_index = (i + 1) % len(hull_points)\n",
    "    plt.plot([hull_points[i, 0], hull_points[next_index, 0]], [hull_points[i, 1], hull_points[next_index, 1]], 'r-')\n",
    "\n",
    "plt.title('Convex Hull Points')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniformity = cv2.contourArea(cnt)/cv2.contourArea(hull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_uniformity(ann_number):\n",
    "    annotation = ann[ann_number, :, :]\n",
    "    annotation = annotation.numpy()\n",
    "    annotation = np.uint8(annotation)\n",
    "    countours, hiearchy = cv2.findContours(annotation, 1, 2)\n",
    "\n",
    "    max_figure = 0\n",
    "    for i in range(1, len(countours)):\n",
    "        if len(countours[i]) > len(countours[max_figure]):\n",
    "            max_figure = i\n",
    "    \n",
    "    cnt = countours[max_figure]\n",
    "    hull = cv2.convexHull(cnt)\n",
    "\n",
    "    uniformity = cv2.contourArea(cnt)/cv2.contourArea(hull)\n",
    "    return uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniformities = []\n",
    "for i in range(ann.shape[0]):\n",
    "    uniformities.append([compute_uniformity(i), i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_uniformities = sorted(uniformities, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_UNIFORMITIES = 10\n",
    "top_uniformities = [i[1] for i in sorted_uniformities[:TOP_N_UNIFORMITIES]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 45, 75, 14, 89, 26, 5, 35, 111, 43]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_uniformities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([115, 1532, 2872])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_annotations = []\n",
    "for i in range(ann.shape[0]):\n",
    "    if i in top_uniformities:\n",
    "        subset_annotations.append(ann[i])\n",
    "\n",
    "# subset_annotations = torch.tensor(subset_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_annotations = torch.stack(subset_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1532, 2872])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_annotations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm(prompt_process.plot_to_result(\n",
    "        subset_annotations, \n",
    "        bboxes, \n",
    "        points, \n",
    "        point_label, \n",
    "        True,\n",
    "        args.better_quality, \n",
    "        args.retina, \n",
    "        args.withContours,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ellipse code working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_number = 43\n",
    "annotation = ann[ann_number, :, :]\n",
    "annotation = annotation.numpy()\n",
    "annotation = np.uint8(annotation)\n",
    "countours, hiearchy = cv2.findContours(annotation, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(annotation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_figure = 0\n",
    "for i in range(1, len(countours)):\n",
    "    if len(countours[i]) > len(countours[max_figure]):\n",
    "        max_figure = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = countours[max_figure]\n",
    "M = cv2.moments(cnt)\n",
    "cx = int(M['m10']/M['m00'])\n",
    "cy = int(M['m01']/M['m00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipse = cv2.fitEllipse(cnt)\n",
    "ellipse_array  = cv2.ellipse(annotation.copy(),ellipse,(0,255,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ellipse_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "# plt.imshow(res)\n",
    "plt.imshow(ellipse_array)\n",
    "\n",
    "plt.title('Convex Hull Points')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ellipse_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4, 45, 75, 14, 89, 26, 5, 35, 111, 43]\n",
    "# 26 is circle\n",
    "ann_number = 43\n",
    "annotation = ann[ann_number, :, :]\n",
    "annotation = annotation.numpy()\n",
    "annotation = np.uint8(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(annotation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "cannotation = cv2.cvtColor(annotation, cv2.COLOR_GRAY2BGR)\n",
    "edges = cv2.Canny(cannotation, threshold1=0, threshold2=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_contour_idx = 0\n",
    "for i, contour in enumerate(contours):\n",
    "    if len(contour) > len(contours[max_contour_idx]):\n",
    "        max_contour_idx = i\n",
    "\n",
    "max_contour = contours[max_contour_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ellipse_img = annotation.copy()\n",
    "\n",
    "ellipse = cv2.fitEllipse(max_contour)\n",
    "cv2.ellipse(ellipse_img, ellipse, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ellipse_area(ellipse_info):\n",
    "    return ellipse[1][0] * ellipse[1][1] * math.pi / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1962.7763671875, 80.90850830078125),\n",
       " (202.6011962890625, 343.9454650878906),\n",
       " 5.11801815032959)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54729.49923142627"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_ellipse_area(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ellipse_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782 2203\n"
     ]
    }
   ],
   "source": [
    "min_col = 0\n",
    "for i in range(annotation.shape[1]):\n",
    "    if annotation[:, i].sum() > 0:\n",
    "        min_col = i\n",
    "        break\n",
    "\n",
    "max_col = annotation.shape[1] - 1\n",
    "for i in range(annotation.shape[1] - 1, -1, -1):\n",
    "    if annotation[:, i].sum() > 0:\n",
    "        max_col = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_row = 0\n",
    "\n",
    "for i in range(annotation.shape[0]):\n",
    "    if annotation[i, :].sum() > 0:\n",
    "        min_row = i\n",
    "        break\n",
    "\n",
    "max_row = annotation.shape[1] - 1\n",
    "for i in range(annotation.shape[0]-1, -1, -1):\n",
    "    if annotation[i, :].sum() > 0:\n",
    "        max_row = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1782, 2203, 516, 808)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_col, max_col, min_row, max_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('FastSAM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b40b0b6b7153b7fb7eb7b1646a512392902d16c990c272c9c20eb9771d9192c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
